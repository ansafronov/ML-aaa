{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virgin-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "def get_mape(y_predict, y_true):\n",
    "    return (abs(y_predict - y_true) / y_true).mean()\n",
    "\n",
    "def process_rooms_number(x):\n",
    "        \n",
    "    if pd.isna(x):\n",
    "        return 1\n",
    "    \n",
    "    if isinstance(x, int):\n",
    "        return x\n",
    "    \n",
    "    if x.isdigit():\n",
    "        return int(x)\n",
    "    \n",
    "    if x == 'Студия':\n",
    "        return 1\n",
    "    \n",
    "    if x == 'Своб. планировка':\n",
    "        return 1\n",
    "    \n",
    "    if x == '> 9':\n",
    "        return 10\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-bahamas",
   "metadata": {},
   "source": [
    "<h3>Реализуем линейную регрессию</h3>\n",
    "\n",
    "<p>Чаще всего алгоритмы машинного обучения реализуются в виде классов с обязательными методами <code>.fit()</code>, <code>.predict()</code>. </p>\n",
    "\n",
    "<p><code>.fit()</code> – обучить алгоритм на обучающей выборке;</p>\n",
    "\n",
    "<p><code>.predict()</code> – сделать предсказание на тестовых данных.</p>\n",
    "\n",
    "<p> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, max_iter=1e4, lr=0.001, tol=0.001, print_every=100):\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        self.check_regression_X_y(X_train, y_train)\n",
    "        self.check_regression_X_y(X_val, y_val)\n",
    "        \n",
    "        n, m = X_train.shape\n",
    "        \n",
    "        self.weights = np.zeros((m, 1))\n",
    "        self.bias = np.median(y_train)\n",
    "        \n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "        \n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "            \n",
    "\n",
    "            dJdw, dJdb = self.grads(X_train, y_train)\n",
    "                \n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "                \n",
    "            self.weights = self.weights - self.lr * \n",
    "            self.bias = ...\n",
    "            \n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def grads(self, X, y):\n",
    "        \n",
    "        self.check_grads(dJdw, dJdb)\n",
    "        \n",
    "        return dJdw, dJdb\n",
    "    \n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "        \n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "        \n",
    "        MAPE_train = get_mape(train_preds, y_train)\n",
    "        MAPE_val = get_mape(val_preds, y_val)\n",
    "        \n",
    "        print(f'{n_iter} completed. MAPE on train: {MAPE_train}, val: {MAPE_val},  grad norm: {gradient_norm}')\n",
    "        \n",
    "        \n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "        \n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным '\n",
    "                             f'числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "            \n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "            \n",
    "        \n",
    "    @staticmethod\n",
    "    def check_regression_X_y(X, y):\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "            \n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "            \n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "            \n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "                    \n",
    "        if np.any([(not isinstance(value, numbers.Real)) for value in y.flatten()]):\n",
    "            raise ValueError(f'Ответы на объектах должны быть действительными числами!')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-photographer",
   "metadata": {},
   "source": [
    "<h3>Тестируем модель на простой задаче</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "y = np.array([[1], [2], [3], [4]])\n",
    "model = LinearRegression(lr=0.1)\n",
    "model.fit(X, y, X, y)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-longitude",
   "metadata": {},
   "source": [
    "<h3>Решаем задачу предсказания цены</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fleet-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('real_estate_novosibirsk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-chorus",
   "metadata": {},
   "source": [
    "<p>Чистим данные:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "korean-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['item_id'], keep='last')\n",
    "data = data.dropna(subset=['area'])\n",
    "data['rooms_number'] = data['rooms_number'].apply(process_rooms_number).copy()\n",
    "data = data[(data.price > 970000) & (data.price < 12700000)]\n",
    "data = data[(data.floor < 59)]\n",
    "\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disturbed-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, train_price, val_price = train_test_split(data.drop('price', axis=1), data['price'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brutal-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_price_estimator.csv')\n",
    "test, test_price = test_data.drop('price', axis=1), test_data['price']\n",
    "\n",
    "y_train = train_price.values.reshape(-1, 1)\n",
    "y_val = val_price.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-singer",
   "metadata": {},
   "source": [
    "### Делаем бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mape(y_predict=np.median(y_train), y_true=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-blade",
   "metadata": {},
   "source": [
    "### Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-square",
   "metadata": {},
   "source": [
    "1) Начинаем с простого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['area']].values\n",
    "X_val = val[['area']].values\n",
    "\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=140000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-easter",
   "metadata": {},
   "source": [
    "<p>Для того, чтобы начать ориентироваться в метрике решения задачи, очень важно построить одну или несколько простых моделей. Часто есть соблазн добавить все признаки сразу и обучить модель — мы так поступать не будем. Наоборот, мы будем постепенно добавлять признаки и следить за тем, что модель решает задачу лучше и лучше. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-motorcycle",
   "metadata": {},
   "source": [
    "2) Увеличиваем количество признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['area', 'floors_in_house', 'floor']].values\n",
    "X_val = val[['area', 'floors_in_house', 'floor']].values\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-telling",
   "metadata": {},
   "source": [
    "Делаем новые признаки\n",
    "##### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_example = pd.DataFrame({'feature': ['a', 'b', 'a', 'c']})\n",
    "ohe_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit_transform(ohe_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_house_type_transformer = OneHotEncoder(sparse=False)\n",
    "train_ohe_house_type = ohe_house_type_transformer.fit_transform(train[['type_of_house']])\n",
    "val_ohe_house_type = ohe_house_type_transformer.transform(val[['type_of_house']])\n",
    "\n",
    "ohe_district_transformer = OneHotEncoder(sparse=False)\n",
    "train_ohe_district = ohe_district_transformer.fit_transform(train[['district']])\n",
    "val_ohe_district = ohe_district_transformer.transform(val[['district']])\n",
    "\n",
    "X_train_extended = np.hstack([X_train, train_ohe_house_type, train_ohe_district])\n",
    "X_val_extended = np.hstack([X_val, val_ohe_house_type, val_ohe_district])\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train_extended, y_train, X_val_extended, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-grammar",
   "metadata": {},
   "source": [
    "### Задание на семинаре: попробовать улучшить метрику MAPE до 15.8% (топ-1 без ML с первой недели).\n",
    "\n",
    "Варианты путей для улучшения:\n",
    "\n",
    "    1) Делать новые признаки из существующих;\n",
    "    2) Препроцессинг данных, целевой переменной - постпроцессинг ответов модели;\n",
    "    3) Анализ ошибок модели –> генерация идей;\n",
    "    4) Добавить регуляризацию;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-drink",
   "metadata": {},
   "source": [
    "<h3>Задание на семинаре: реализуем логистическую регрессию</h3>\n",
    "\n",
    "<p>Мы получаем оптимальные веса алгоритма градиентным спуском:</p>\n",
    "\n",
    "<p style=\"text-align:center\"><br />\n",
    "<br />\n",
    "<span class=\"math-tex\">\\(\\begin{bmatrix} w_{1}^{t+1}\\\\  ...\\\\ w_{m}^{t+1}\\\\  \\end{bmatrix} = \\begin{bmatrix} w_{1}^{t}\\\\  ...\\\\ w_{m}^{t}\\\\  \\end{bmatrix} - \\alpha \\cdot  \\begin{bmatrix} \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})x_{1}^{(i)}\\\\  ...\\\\ \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})x_{m}^{(i)}\\\\  \\end{bmatrix}\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(b^{t+1} = b^{t} - \\alpha \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, max_iter=1e4, lr=0.001, tol=0.001, print_every=100):\n",
    "        \n",
    "        '''\n",
    "        max_iter – максимальное количеств\n",
    "        '''\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        '''\n",
    "        Обучение модели.\n",
    "        \n",
    "        X_train – матрица объектов для обучения\n",
    "        y_train – ответы на объектах для обучения\n",
    "        \n",
    "        X_val – матрица объектов для валидации\n",
    "        y_val – ответы на объектах для валидации\n",
    "        '''\n",
    "        \n",
    "        self.check_binary_clf_X_y(X_train, y_train)\n",
    "        self.check_binary_clf_X_y(X_val, y_val)\n",
    "                \n",
    "        n, m = X_train.shape\n",
    "        \n",
    "        self.weights = \n",
    "        self.bias = \n",
    "        \n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "        \n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "            \n",
    "            dJdw, dJdb = self.grads(X_train, y_train)\n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "                \n",
    "            self.weights = \n",
    "            self.bias = \n",
    "            \n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):  \n",
    "        \n",
    "        '''\n",
    "        Метод возвращает предсказанную метку класса на объектах X\n",
    "        '''\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        '''\n",
    "        Метод возвращает вероятность класса 1 на объектах X\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def grads(self, x, y):\n",
    "        \n",
    "        '''\n",
    "        Рассчёт градиентов\n",
    "        '''\n",
    "        y_hat = \n",
    "        \n",
    "        dJdw = \n",
    "        dJdb = \n",
    "        \n",
    "        self.check_grads(dJdw, dJdb)\n",
    "        \n",
    "        return dJdw, dJdb\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        '''\n",
    "        Сигмоида от x\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "        \n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "        \n",
    "        train_acc = accuracy_score(train_preds, y_train)\n",
    "        val_acc = accuracy_score(val_preds, y_val)\n",
    "        \n",
    "        print(f'{n_iter} completed. accuracy_score on train: {train_acc}, val: {val_acc}, grad_norm: {gradient_norm}')\n",
    "        \n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "        \n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным'\n",
    "                             f' числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "            \n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_binary_clf_X_y(X, y):\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "            \n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "            \n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "            \n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "\n",
    "                    \n",
    "        if sorted(np.unique([1, 0, 0])) != [0, 1]:\n",
    "            raise ValueError(f'Ответы на объектах должны быть только 0 или 1, а у нас np.unique(y) = {np.unique(y)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-cable",
   "metadata": {},
   "source": [
    "<h2>Домашнее задание</h2>\n",
    "\n",
    "<p>Воспользуемся реализованной моделью логистической регрессии, чтобы решить задачу определения пола пользователя Авито.</p>\n",
    "\n",
    "<p><a href=\"https://stepik.org/media/attachments/lesson/527992/binary_clf_data.csv\" rel=\"noopener noreferrer nofollow\">Данные</a> даны в сыром виде &ndash; айтемы и их категории, которые выкладывали покупатели на Авито. Целевая переменная: <em>gender.</em></p>\n",
    "\n",
    "<p>Вам необходимо разбить данные на train, val. Перед загрузкой файла с ответом убедитесь, что точность (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\" rel=\"noopener noreferrer nofollow\">accuracy</a>)&nbsp;на валидации не менее 0.7.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><strong>План действий</strong></p>\n",
    "\n",
    "<p>Сначала нужно преобразовать категории с помощью one-hot encoding. Далее необходимо агрегировать категории, в которых пользователи выкладывали объявления, чтобы получить вектор признаков для каждого объекта. В результате у каждого пользователя будет вектор признаков, содержащий количество айтемов, выложенных в каждой из возможных категорий.</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Убедитесь, что для каждого пользователя в выборке есть только один объект, каждый признак означает количество айтемов, выложенное этим пользователем в категории;</li>\n",
    "\t<li>Убедитесь, что после one-hot энкодинга каждая категория соответствует признаку,&nbsp;<strong>одинаковому в train, val и test.</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>Попробуйте варианты отбора признаков. Для борьбы с переобучением на редких категориях используйте регуляризацию. В качестве&nbsp;ответа загрузите файл с предсказанием пола для пользователей:</p>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<table align=\"center\" border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px\">\n",
    "\t<thead>\n",
    "\t\t<tr>\n",
    "\t\t\t<th style=\"text-align:center\">user_id</th>\n",
    "\t\t\t<th style=\"text-align:center\">gender</th>\n",
    "\t\t</tr>\n",
    "\t</thead>\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"text-align:center\">15424171</td>\n",
    "\t\t\t<td style=\"text-align:center\">male</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"text-align:center\">15454025</td>\n",
    "\t\t\t<td style=\"text-align:center\">female</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<p>Такой файл можно сформировать с помощью&nbsp;<code>test_predictions.to_csv(&#39;test_predictions.csv&#39;, index=False)</code>.</p>\n",
    "\n",
    "<p>После того, как получилось обучить модель, ответьте на вопрос: какие из категорий вносят наибольший вклад в вероятность класса &quot;мужчина&quot; и класса &quot;женщина&quot;?</p>\n",
    "\n",
    "<p>Например, если вы закодировали &quot;мужчина&quot; как 1, большие положительные веса при признаках будут означать большой вклад в вероятность класса 1, большие по модулю отрицательные веса будут вносить наибольший вклад в вероятность класса 0. Согласуется ли полученный результат с вашим жизненным опытом?</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
