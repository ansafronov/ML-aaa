{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virgin-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "def get_mape(y_predict, y_true):\n",
    "    return (abs(y_predict - y_true) / y_true).mean()\n",
    "\n",
    "def process_rooms_number(x):\n",
    "        \n",
    "    if pd.isna(x):\n",
    "        return 1\n",
    "    \n",
    "    if isinstance(x, int):\n",
    "        return x\n",
    "    \n",
    "    if x.isdigit():\n",
    "        return int(x)\n",
    "    \n",
    "    if x == 'Студия':\n",
    "        return 1\n",
    "    \n",
    "    if x == 'Своб. планировка':\n",
    "        return 1\n",
    "    \n",
    "    if x == '> 9':\n",
    "        return 10\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-bahamas",
   "metadata": {},
   "source": [
    "<h3>Реализуем линейную регрессию</h3>\n",
    "\n",
    "<p>Чаще всего алгоритмы машинного обучения реализуются в виде классов с обязательными методами <code>.fit()</code>, <code>.predict()</code>. </p>\n",
    "\n",
    "<p><code>.fit()</code> – обучить алгоритм на обучающей выборке;</p>\n",
    "\n",
    "<p><code>.predict()</code> – сделать предсказание на тестовых данных.</p>\n",
    "\n",
    "<p> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pediatric-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, max_iter=1e4, lr=0.001, tol=0.001, print_every=100):\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        self.check_regression_X_y(X_train, y_train)\n",
    "        self.check_regression_X_y(X_val, y_val)\n",
    "        \n",
    "        n, m = X_train.shape\n",
    "        \n",
    "        self.weights = np.zeros((m, 1))\n",
    "        self.bias = np.median(y_train)\n",
    "        \n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "        \n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "            dJdw, dJdb = self.grads(X_train, y_train)\n",
    "                \n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "                \n",
    "            self.weights = self.weights - self.lr * dJdw\n",
    "            self.bias = self.bias - self.lr * dJdb\n",
    "            \n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.weights + self.bias\n",
    "    \n",
    "    def grads(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        \n",
    "        dJdw = 2 * (X.T @ (y - y_hat)) / len(X)\n",
    "        dJdb = 2 * (y - y_hat).mean()\n",
    "        \n",
    "        self.check_grads(dJdw, dJdb)\n",
    "        \n",
    "        return dJdw, dJdb\n",
    "    \n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "        \n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "        \n",
    "        MAPE_train = get_mape(train_preds, y_train)\n",
    "        MAPE_val = get_mape(val_preds, y_val)\n",
    "        \n",
    "        print(f'{n_iter} completed. MAPE on train: {MAPE_train}, val: {MAPE_val},  grad norm: {gradient_norm}')\n",
    "        \n",
    "        \n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "        \n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным '\n",
    "                             f'числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "            \n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "            \n",
    "        \n",
    "    @staticmethod\n",
    "    def check_regression_X_y(X, y):\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "            \n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "            \n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "            \n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "                    \n",
    "        if np.any([(not isinstance(value, numbers.Real)) for value in y.flatten()]):\n",
    "            raise ValueError(f'Ответы на объектах должны быть действительными числами!')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-photographer",
   "metadata": {},
   "source": [
    "<h3>Тестируем модель на простой задаче</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "painted-cycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 completed. MAPE on train: 6155844252290.813, val: 6155844252290.813,  grad norm: 26474050542701.258\n",
      "200 completed. MAPE on train: 3.654498472642654e+26, val: 3.654498472642654e+26,  grad norm: 1.571667074529458e+27\n",
      "300 completed. MAPE on train: 2.169541420987484e+40, val: 2.169541420987484e+40,  grad norm: 9.33040975039231e+40\n",
      "400 completed. MAPE on train: 1.2879769994750372e+54, val: 1.2879769994750372e+54,  grad norm: 5.5391213267148074e+54\n",
      "500 completed. MAPE on train: 7.64624604595779e+67, val: 7.64624604595779e+67,  grad norm: 3.2883727395548445e+68\n",
      "600 completed. MAPE on train: 4.539295237349328e+81, val: 4.539295237349328e+81,  grad norm: 1.9521860303176892e+82\n",
      "700 completed. MAPE on train: 2.6948127392153814e+95, val: 2.6948127392153814e+95,  grad norm: 1.1589410929989182e+96\n",
      "800 completed. MAPE on train: 1.599811274597352e+109, val: 1.599811274597352e+109,  grad norm: 6.880207296755176e+109\n",
      "900 completed. MAPE on train: 9.497491521707706e+122, val: 9.497491521707706e+122,  grad norm: 4.0845261879386404e+123\n",
      "1000 completed. MAPE on train: 5.638311633202636e+136, val: 5.638311633202636e+136,  grad norm: 2.424833069757176e+137\n",
      "1100 completed. MAPE on train: 3.34725837874631e+150, val: 3.34725837874631e+150,  grad norm: 1.4395342680261783e+151\n",
      "1200 completed. MAPE on train: 1.987144269945802e+164, val: 1.987144269945802e+164,  grad norm: inf\n",
      "1300 completed. MAPE on train: 1.1796945149652305e+178, val: 1.1796945149652305e+178,  grad norm: inf\n",
      "1400 completed. MAPE on train: 7.003412734984798e+191, val: 7.003412734984798e+191,  grad norm: inf\n",
      "1500 completed. MAPE on train: 4.157668728161618e+205, val: 4.157668728161618e+205,  grad norm: inf\n",
      "1600 completed. MAPE on train: 2.468255107510891e+219, val: 2.468255107510891e+219,  grad norm: inf\n",
      "1700 completed. MAPE on train: 1.4653123358501445e+233, val: 1.4653123358501445e+233,  grad norm: inf\n",
      "1800 completed. MAPE on train: 8.699020757866027e+246, val: 8.699020757866027e+246,  grad norm: inf\n",
      "1900 completed. MAPE on train: 5.164288888749451e+260, val: 5.164288888749451e+260,  grad norm: inf\n",
      "2000 completed. MAPE on train: 3.06584849821688e+274, val: 3.06584849821688e+274,  grad norm: inf\n",
      "2100 completed. MAPE on train: 1.8200815671825818e+288, val: 1.8200815671825818e+288,  grad norm: inf\n",
      "2200 completed. MAPE on train: 1.0805155287759628e+302, val: 1.0805155287759628e+302,  grad norm: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/57cvqk9113964s_8bqbv05mh0000gq/T/ipykernel_5380/3207333840.py:47: RuntimeWarning: overflow encountered in multiply\n",
      "  dJdw = 2 * (X.T @ (y - y_hat)) / len(X)\n",
      "/Users/a.safronov/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:179: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/var/folders/k3/57cvqk9113964s_8bqbv05mh0000gq/T/ipykernel_5380/3207333840.py:42: RuntimeWarning: invalid value encountered in matmul\n",
      "  return X @ self.weights + self.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "y = np.array([[1], [2], [3], [4]])\n",
    "model = LinearRegression(lr=0.1)\n",
    "model.fit(X, y, X, y)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-longitude",
   "metadata": {},
   "source": [
    "<h3>Решаем задачу предсказания цены</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fleet-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('real_estate_novosibirsk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8c8eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, train_price, val_price = train_test_split(data.drop('price', axis=1), data['price'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61978b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['min_floor_district'] = 0\n",
    "train['max_floor_district'] = 0\n",
    "val['min_floor_district'] = 0\n",
    "val['max_floor_district'] = 0\n",
    "for d in train['district'].unique():\n",
    "    subsample = train.loc[data['district'] == d, 'floor']\n",
    "    \n",
    "    \n",
    "    train.loc[subsample[subsample == subsample.min()].index, 'min_floor_district'] = 1\n",
    "    data.loc[subsample[subsample == subsample.max()].index, 'max_floor_district'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff4152ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36914\n",
       "1       48\n",
       "Name: max_floor_district, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max_floor_district.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-chorus",
   "metadata": {},
   "source": [
    "<p>Чистим данные:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "korean-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['item_id'], keep='last')\n",
    "data = data.dropna(subset=['area'])\n",
    "data['rooms_number'] = data['rooms_number'].apply(process_rooms_number).copy()\n",
    "data = data[(data.price > 970000) & (data.price < 12700000)]\n",
    "data = data[(data.floor < 59)]\n",
    "\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "disturbed-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, train_price, val_price = train_test_split(data.drop('price', axis=1), data['price'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "brutal-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_price_estimator.csv')\n",
    "test, test_price = test_data.drop('price', axis=1), test_data['price']\n",
    "\n",
    "y_train = train_price.values.reshape(-1, 1)\n",
    "y_val = val_price.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-singer",
   "metadata": {},
   "source": [
    "### Делаем бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mape(y_predict=np.median(y_train), y_true=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-blade",
   "metadata": {},
   "source": [
    "### Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-square",
   "metadata": {},
   "source": [
    "1) Начинаем с простого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['area']].values\n",
    "X_val = val[['area']].values\n",
    "\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=140000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-easter",
   "metadata": {},
   "source": [
    "<p>Для того, чтобы начать ориентироваться в метрике решения задачи, очень важно построить одну или несколько простых моделей. Часто есть соблазн добавить все признаки сразу и обучить модель — мы так поступать не будем. Наоборот, мы будем постепенно добавлять признаки и следить за тем, что модель решает задачу лучше и лучше. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-motorcycle",
   "metadata": {},
   "source": [
    "2) Увеличиваем количество признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24106846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[data['price'] < 20000000]['price'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2912015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='area'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[['area', 'price']].set_index('area').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['area', 'floors_in_house', 'floor']].values\n",
    "X_val = val[['area', 'floors_in_house', 'floor']].values\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-telling",
   "metadata": {},
   "source": [
    "Делаем новые признаки\n",
    "##### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_example = pd.DataFrame({'feature': ['a', 'b', 'a', 'c']})\n",
    "ohe_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit_transform(ohe_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "moved-confusion",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m ohe_house_type_transformer \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m train_ohe_house_type \u001b[38;5;241m=\u001b[39m ohe_house_type_transformer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mtrain\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype_of_house\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      3\u001b[0m val_ohe_house_type \u001b[38;5;241m=\u001b[39m ohe_house_type_transformer\u001b[38;5;241m.\u001b[39mtransform(val[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype_of_house\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      5\u001b[0m ohe_district_transformer \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "ohe_house_type_transformer = OneHotEncoder(sparse=False)\n",
    "train_ohe_house_type = ohe_house_type_transformer.fit_transform(train[['type_of_house']])\n",
    "val_ohe_house_type = ohe_house_type_transformer.transform(val[['type_of_house']])\n",
    "\n",
    "ohe_district_transformer = OneHotEncoder(sparse=False)\n",
    "train_ohe_district = ohe_district_transformer.fit_transform(train[['district']])\n",
    "val_ohe_district = ohe_district_transformer.transform(val[['district']])\n",
    "\n",
    "X_train_extended = np.hstack([X_train, train_ohe_house_type, train_ohe_district])\n",
    "X_val_extended = np.hstack([X_val, val_ohe_house_type, val_ohe_district])\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train_extended, y_train, X_val_extended, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-grammar",
   "metadata": {},
   "source": [
    "### Задание на семинаре: попробовать улучшить метрику MAPE до 15.8% (топ-1 без ML с первой недели).\n",
    "\n",
    "Варианты путей для улучшения:\n",
    "\n",
    "    1) Делать новые признаки из существующих;\n",
    "    2) Препроцессинг данных, целевой переменной - постпроцессинг ответов модели;\n",
    "    3) Анализ ошибок модели –> генерация идей;\n",
    "    4) Добавить регуляризацию;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-drink",
   "metadata": {},
   "source": [
    "<h3>Задание на семинаре: реализуем логистическую регрессию</h3>\n",
    "\n",
    "<p>Мы получаем оптимальные веса алгоритма градиентным спуском:</p>\n",
    "\n",
    "<p style=\"text-align:center\"><br />\n",
    "<br />\n",
    "<span class=\"math-tex\">\\(\\begin{bmatrix} w_{1}^{t+1}\\\\  ...\\\\ w_{m}^{t+1}\\\\  \\end{bmatrix} = \\begin{bmatrix} w_{1}^{t}\\\\  ...\\\\ w_{m}^{t}\\\\  \\end{bmatrix} - \\alpha \\cdot  \\begin{bmatrix} \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})x_{1}^{(i)}\\\\  ...\\\\ \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})x_{m}^{(i)}\\\\  \\end{bmatrix}\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(b^{t+1} = b^{t} - \\alpha \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, max_iter=1e4, lr=0.001, tol=0.001, print_every=100):\n",
    "        \n",
    "        '''\n",
    "        max_iter – максимальное количеств\n",
    "        '''\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        '''\n",
    "        Обучение модели.\n",
    "        \n",
    "        X_train – матрица объектов для обучения\n",
    "        y_train – ответы на объектах для обучения\n",
    "        \n",
    "        X_val – матрица объектов для валидации\n",
    "        y_val – ответы на объектах для валидации\n",
    "        '''\n",
    "        \n",
    "        self.check_binary_clf_X_y(X_train, y_train)\n",
    "        self.check_binary_clf_X_y(X_val, y_val)\n",
    "                \n",
    "        n, m = X_train.shape\n",
    "        \n",
    "        self.weights = \n",
    "        self.bias = \n",
    "        \n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "        \n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "            \n",
    "            dJdw, dJdb = self.grads(X_train, y_train)\n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "                \n",
    "            self.weights = \n",
    "            self.bias = \n",
    "            \n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):  \n",
    "        \n",
    "        '''\n",
    "        Метод возвращает предсказанную метку класса на объектах X\n",
    "        '''\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        '''\n",
    "        Метод возвращает вероятность класса 1 на объектах X\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def grads(self, x, y):\n",
    "        \n",
    "        '''\n",
    "        Рассчёт градиентов\n",
    "        '''\n",
    "        y_hat = \n",
    "        \n",
    "        dJdw = \n",
    "        dJdb = \n",
    "        \n",
    "        self.check_grads(dJdw, dJdb)\n",
    "        \n",
    "        return dJdw, dJdb\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        '''\n",
    "        Сигмоида от x\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "        \n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "        \n",
    "        train_acc = accuracy_score(train_preds, y_train)\n",
    "        val_acc = accuracy_score(val_preds, y_val)\n",
    "        \n",
    "        print(f'{n_iter} completed. accuracy_score on train: {train_acc}, val: {val_acc}, grad_norm: {gradient_norm}')\n",
    "        \n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "        \n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным'\n",
    "                             f' числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "            \n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_binary_clf_X_y(X, y):\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "            \n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "            \n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "            \n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "\n",
    "                    \n",
    "        if sorted(np.unique([1, 0, 0])) != [0, 1]:\n",
    "            raise ValueError(f'Ответы на объектах должны быть только 0 или 1, а у нас np.unique(y) = {np.unique(y)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-cable",
   "metadata": {},
   "source": [
    "<h2>Домашнее задание</h2>\n",
    "\n",
    "<p>Воспользуемся реализованной моделью логистической регрессии, чтобы решить задачу определения пола пользователя Авито.</p>\n",
    "\n",
    "<p><a href=\"https://stepik.org/media/attachments/lesson/527992/binary_clf_data.csv\" rel=\"noopener noreferrer nofollow\">Данные</a> даны в сыром виде &ndash; айтемы и их категории, которые выкладывали покупатели на Авито. Целевая переменная: <em>gender.</em></p>\n",
    "\n",
    "<p>Вам необходимо разбить данные на train, val. Перед загрузкой файла с ответом убедитесь, что точность (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\" rel=\"noopener noreferrer nofollow\">accuracy</a>)&nbsp;на валидации не менее 0.7.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><strong>План действий</strong></p>\n",
    "\n",
    "<p>Сначала нужно преобразовать категории с помощью one-hot encoding. Далее необходимо агрегировать категории, в которых пользователи выкладывали объявления, чтобы получить вектор признаков для каждого объекта. В результате у каждого пользователя будет вектор признаков, содержащий количество айтемов, выложенных в каждой из возможных категорий.</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Убедитесь, что для каждого пользователя в выборке есть только один объект, каждый признак означает количество айтемов, выложенное этим пользователем в категории;</li>\n",
    "\t<li>Убедитесь, что после one-hot энкодинга каждая категория соответствует признаку,&nbsp;<strong>одинаковому в train, val и test.</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>Попробуйте варианты отбора признаков. Для борьбы с переобучением на редких категориях используйте регуляризацию. В качестве&nbsp;ответа загрузите файл с предсказанием пола для пользователей:</p>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<table align=\"center\" border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px\">\n",
    "\t<thead>\n",
    "\t\t<tr>\n",
    "\t\t\t<th style=\"text-align:center\">user_id</th>\n",
    "\t\t\t<th style=\"text-align:center\">gender</th>\n",
    "\t\t</tr>\n",
    "\t</thead>\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"text-align:center\">15424171</td>\n",
    "\t\t\t<td style=\"text-align:center\">male</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"text-align:center\">15454025</td>\n",
    "\t\t\t<td style=\"text-align:center\">female</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<p>Такой файл можно сформировать с помощью&nbsp;<code>test_predictions.to_csv(&#39;test_predictions.csv&#39;, index=False)</code>.</p>\n",
    "\n",
    "<p>После того, как получилось обучить модель, ответьте на вопрос: какие из категорий вносят наибольший вклад в вероятность класса &quot;мужчина&quot; и класса &quot;женщина&quot;?</p>\n",
    "\n",
    "<p>Например, если вы закодировали &quot;мужчина&quot; как 1, большие положительные веса при признаках будут означать большой вклад в вероятность класса 1, большие по модулю отрицательные веса будут вносить наибольший вклад в вероятность класса 0. Согласуется ли полученный результат с вашим жизненным опытом?</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
