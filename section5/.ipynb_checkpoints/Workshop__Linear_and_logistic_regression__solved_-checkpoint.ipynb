{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "virgin-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "def get_mape(y_predict, y_true):\n",
    "    return (abs(y_predict - y_true) / y_true).mean()\n",
    "\n",
    "def process_rooms_number(x):\n",
    "        \n",
    "    if pd.isna(x):\n",
    "        return 1\n",
    "    \n",
    "    if isinstance(x, int):\n",
    "        return x\n",
    "    \n",
    "    if x.isdigit():\n",
    "        return int(x)\n",
    "    \n",
    "    if x == 'Студия':\n",
    "        return 1\n",
    "    \n",
    "    if x == 'Своб. планировка':\n",
    "        return 1\n",
    "    \n",
    "    if x == '> 9':\n",
    "        return 10\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-bahamas",
   "metadata": {},
   "source": [
    "<h3>Реализуем линейную регрессию</h3>\n",
    "\n",
    "<p>Чаще всего алгоритмы машинного обучения реализуются в виде классов с обязательными методами <code>.fit()</code>, <code>.predict()</code>. </p>\n",
    "\n",
    "<p><code>.fit()</code> – обучить алгоритм на обучающей выборке;</p>\n",
    "\n",
    "<p><code>.predict()</code> – сделать предсказание на тестовых данных.</p>\n",
    "\n",
    "<p> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pediatric-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, max_iter=1e4, lr=0.001, tol=0.001, print_every=100, batch_size=None):\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        self.check_regression_X_y(X_train, y_train)\n",
    "        self.check_regression_X_y(X_val, y_val)\n",
    "        \n",
    "        n, m = X_train.shape\n",
    "        \n",
    "        self.weights = np.zeros((m, 1))\n",
    "        self.bias = 0\n",
    "        \n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "        \n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "            \n",
    "            if self.batch_size:\n",
    "                random_ids = np.random.randint(0, X_train.shape[0], size=self.batch_size)\n",
    "                dJdw, dJdb = self.grads(X_train[random_ids], y_train[random_ids])\n",
    "            else:\n",
    "                dJdw, dJdb = self.grads(X_train, y_train)\n",
    "                \n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "                \n",
    "            self.weights = self.weights - self.lr * dJdw\n",
    "            self.bias = self.bias - self.lr * dJdb\n",
    "            \n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.weights) + self.bias\n",
    "    \n",
    "    def grads(self, X, y):\n",
    "        \n",
    "        y_hat = self.predict(X)\n",
    "        \n",
    "        dJdw = ((y_hat - y) * X).mean(axis=0, keepdims=True).T\n",
    "        dJdb = (y_hat - y).mean()\n",
    "        \n",
    "        self.check_grads(dJdw, dJdb)\n",
    "        \n",
    "        return dJdw, dJdb\n",
    "    \n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "        \n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "        \n",
    "        MAPE_train = get_mape(train_preds, y_train)\n",
    "        MAPE_val = get_mape(val_preds, y_val)\n",
    "        \n",
    "        print(f'{n_iter} completed. MAPE on train: {MAPE_train}, val: {MAPE_val},  grad norm: {gradient_norm}')\n",
    "        \n",
    "        \n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "        \n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным '\n",
    "                             f'числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "            \n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "            \n",
    "        \n",
    "    @staticmethod\n",
    "    def check_regression_X_y(X, y):\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "            \n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "            \n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "            \n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "                    \n",
    "        if np.any([(not isinstance(value, numbers.Real)) for value in y.flatten()]):\n",
    "            raise ValueError(f'Ответы на объектах должны быть действительными числами!')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-photographer",
   "metadata": {},
   "source": [
    "<h3>Тестируем модель на простой задаче</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painted-cycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 completed. MAPE on train: 0.04256362465226591, val: 0.04256362465226591,  grad norm: 0.034121612608709384\n",
      "200 completed. MAPE on train: 0.006958616076559935, val: 0.006958616076559935,  grad norm: 0.005261242720739285\n",
      "300 completed. MAPE on train: 0.0016163910724505959, val: 0.0016163910724505959,  grad norm: 0.0012425153423383014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.00251522],\n",
       "       [2.0021799 ],\n",
       "       [3.00184458],\n",
       "       [3.9962243 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "y = np.array([[1], [2], [3], [4]])\n",
    "model = LinearRegression(lr=0.1)\n",
    "model.fit(X, y, X, y)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-longitude",
   "metadata": {},
   "source": [
    "<h3>Решаем задачу предсказания цены</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fleet-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('real_estate_novosibirsk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-chorus",
   "metadata": {},
   "source": [
    "<p>Чистим данные:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "korean-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['item_id'], keep='last')\n",
    "data = data.dropna(subset=['area'])\n",
    "data['rooms_number'] = data['rooms_number'].apply(process_rooms_number).copy()\n",
    "data = data[(data.price > 970000) & (data.price < 12700000)]\n",
    "data = data[(data.floor < 59)]\n",
    "\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "disturbed-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, train_price, val_price = train_test_split(data.drop('price', axis=1), data['price'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brutal-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_price_estimator.csv')\n",
    "test, test_price = test_data.drop('price', axis=1), test_data['price']\n",
    "\n",
    "y_train = train_price.values.reshape(-1, 1)\n",
    "y_val = val_price.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-singer",
   "metadata": {},
   "source": [
    "### Делаем бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "entitled-copper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37614684131639187"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mape(y_predict=np.median(y_train), y_true=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-blade",
   "metadata": {},
   "source": [
    "### Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-square",
   "metadata": {},
   "source": [
    "1) Начинаем с простого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "every-irish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.24029516677001161, val: 0.2329548344266407,  grad norm: 30117.246683941412\n",
      "20000 completed. MAPE on train: 0.24561649170433025, val: 0.23809626595209205,  grad norm: 10065.259090318064\n",
      "30000 completed. MAPE on train: 0.24758376339877478, val: 0.24000870731774077,  grad norm: 3363.834736235926\n",
      "40000 completed. MAPE on train: 0.24826169750587387, val: 0.24067095512394918,  grad norm: 1124.2019734584471\n",
      "50000 completed. MAPE on train: 0.2484905934663744, val: 0.24089419268746382,  grad norm: 375.71110837099195\n",
      "60000 completed. MAPE on train: 0.24856727675973736, val: 0.24096893231384187,  grad norm: 125.56359113940078\n",
      "70000 completed. MAPE on train: 0.24859290554408522, val: 0.2409939104837159,  grad norm: 41.96366588207886\n",
      "80000 completed. MAPE on train: 0.24860147161787696, val: 0.2410022627632707,  grad norm: 14.024361984839292\n",
      "90000 completed. MAPE on train: 0.24860433442114063, val: 0.2410050542002018,  grad norm: 4.68697681557556\n",
      "100000 completed. MAPE on train: 0.24860529117714422, val: 0.24100598710539872,  grad norm: 1.5663993620103982\n",
      "110000 completed. MAPE on train: 0.24860561092739095, val: 0.24100629888464625,  grad norm: 0.5234945805885746\n",
      "120000 completed. MAPE on train: 0.2486057177887222, val: 0.24100640308204965,  grad norm: 0.1749531972248751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x13720fc50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[['area']].values\n",
    "X_val = val[['area']].values\n",
    "\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=140000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-easter",
   "metadata": {},
   "source": [
    "<p>Для того, чтобы начать ориентироваться в метрике решения задачи, очень важно построить одну или несколько простых моделей. Часто есть соблазн добавить все признаки сразу и обучить модель — мы так поступать не будем. Наоборот, мы будем постепенно добавлять признаки и следить за тем, что модель решает задачу лучше и лучше. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-motorcycle",
   "metadata": {},
   "source": [
    "2) Увеличиваем количество признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hawaiian-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.239239303245989, val: 0.2310277115583838,  grad norm: 8332.442952614409\n",
      "20000 completed. MAPE on train: 0.23827546525993404, val: 0.23014290821438477,  grad norm: 4220.676071622873\n",
      "30000 completed. MAPE on train: 0.2378179226871759, val: 0.22973006016092237,  grad norm: 2137.9212078469704\n",
      "40000 completed. MAPE on train: 0.23759254600348248, val: 0.22952789014180472,  grad norm: 1082.9324528581403\n",
      "50000 completed. MAPE on train: 0.23748059322083012, val: 0.22942714580093734,  grad norm: 548.5434604180346\n",
      "60000 completed. MAPE on train: 0.23742456135719328, val: 0.2293766424561706,  grad norm: 277.85659869479014\n",
      "70000 completed. MAPE on train: 0.2373964173715967, val: 0.22935133976932084,  grad norm: 140.7441616008451\n",
      "80000 completed. MAPE on train: 0.23738220539305263, val: 0.2293385867011664,  grad norm: 71.29187904062266\n",
      "90000 completed. MAPE on train: 0.23737501173998996, val: 0.22933215167169438,  grad norm: 36.11184975159185\n",
      "100000 completed. MAPE on train: 0.23737136841036557, val: 0.22932889363000197,  grad norm: 18.291924831044653\n",
      "110000 completed. MAPE on train: 0.23736952293548458, val: 0.2293272462516673,  grad norm: 9.265504711757506\n",
      "120000 completed. MAPE on train: 0.23736858845172248, val: 0.22932641207539306,  grad norm: 4.693304742650055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x13720fcf8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[['area', 'floors_in_house', 'floor']].values\n",
    "X_val = val[['area', 'floors_in_house', 'floor']].values\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-telling",
   "metadata": {},
   "source": [
    "Делаем новые признаки\n",
    "##### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "developmental-shoot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature\n",
       "0       a\n",
       "1       b\n",
       "2       a\n",
       "3       c"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_example = pd.DataFrame({'feature': ['a', 'b', 'a', 'c']})\n",
    "ohe_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "remarkable-bedroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit_transform(ohe_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "moved-confusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.20574153313423907, val: 0.19897052723359107,  grad norm: 73613.4370674599\n",
      "20000 completed. MAPE on train: 0.20078939873345766, val: 0.19405926981648305,  grad norm: 47488.322000385386\n",
      "30000 completed. MAPE on train: 0.1984876912735323, val: 0.19177328391822482,  grad norm: 33319.74902378374\n",
      "40000 completed. MAPE on train: 0.1974652599109884, val: 0.19068948920254294,  grad norm: 24085.089355779004\n",
      "50000 completed. MAPE on train: 0.19699635649909036, val: 0.19019131062255176,  grad norm: 17705.309580183795\n",
      "60000 completed. MAPE on train: 0.19681496621490227, val: 0.18997521540795134,  grad norm: 13167.082091590632\n",
      "70000 completed. MAPE on train: 0.1967741031464115, val: 0.18990017553117883,  grad norm: 9886.15040583446\n",
      "80000 completed. MAPE on train: 0.19680183126748424, val: 0.18988869242183626,  grad norm: 7491.058855734913\n",
      "90000 completed. MAPE on train: 0.1968535872530419, val: 0.1899095236650007,  grad norm: 5732.40368552789\n",
      "100000 completed. MAPE on train: 0.19690962578912719, val: 0.1899390518609248,  grad norm: 4437.497953006054\n",
      "110000 completed. MAPE on train: 0.19695893550930932, val: 0.18996970712660075,  grad norm: 3484.4558725676548\n",
      "120000 completed. MAPE on train: 0.19699715218040398, val: 0.18999854351148043,  grad norm: 2785.9100483526367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x13957a0f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_house_type_transformer = OneHotEncoder(sparse=False)\n",
    "train_ohe_house_type = ohe_house_type_transformer.fit_transform(train[['type_of_house']])\n",
    "val_ohe_house_type = ohe_house_type_transformer.transform(val[['type_of_house']])\n",
    "\n",
    "ohe_district_transformer = OneHotEncoder(sparse=False)\n",
    "train_ohe_district = ohe_district_transformer.fit_transform(train[['district']])\n",
    "val_ohe_district = ohe_district_transformer.transform(val[['district']])\n",
    "\n",
    "X_train_extended = np.hstack([X_train, train_ohe_house_type, train_ohe_district])\n",
    "X_val_extended = np.hstack([X_val, val_ohe_house_type, val_ohe_district])\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train_extended, y_train, X_val_extended, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "turned-regulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.22002665898718857, val: 0.212937069925644,  grad norm: 19977810.168034397\n",
      "20000 completed. MAPE on train: 0.19247077869825358, val: 0.18594807095021462,  grad norm: 16980724.488739636\n",
      "30000 completed. MAPE on train: 0.1913386918177149, val: 0.18445481111574968,  grad norm: 13205906.592428094\n",
      "40000 completed. MAPE on train: 0.19112659840879015, val: 0.18417532549662113,  grad norm: 5728877.479752828\n",
      "50000 completed. MAPE on train: 0.1894741602682266, val: 0.1824652776923496,  grad norm: 13815092.006003348\n",
      "60000 completed. MAPE on train: 0.19448523868392742, val: 0.18761447165545547,  grad norm: 2308070.1444851975\n",
      "70000 completed. MAPE on train: 0.19083428483572493, val: 0.18383616806599373,  grad norm: 10612205.959234586\n",
      "80000 completed. MAPE on train: 0.19465468644056347, val: 0.18770703286885573,  grad norm: 3528553.7919574934\n",
      "90000 completed. MAPE on train: 0.3111794832205913, val: 0.30156251433543213,  grad norm: 42145024.87942516\n",
      "100000 completed. MAPE on train: 0.20292582621019892, val: 0.19697607882468188,  grad norm: 30513242.642737582\n",
      "110000 completed. MAPE on train: 0.20246169322267715, val: 0.1954993640561815,  grad norm: 8803602.167111043\n",
      "120000 completed. MAPE on train: 0.19156765206507326, val: 0.18457614039178086,  grad norm: 7540271.17017819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x13957aba8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1, batch_size=8196)\n",
    "model.fit(X_train_extended, y_train, X_val_extended, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-grammar",
   "metadata": {},
   "source": [
    "### Задание на семинаре: попробовать улучшить метрику MAPE до 15.8% (топ-1 без ML с первой недели).\n",
    "\n",
    "Варианты путей для улучшения:\n",
    "\n",
    "    1) Делать новые признаки из существующих;\n",
    "    2) Препроцессинг данных, целевой переменной - постпроцессинг ответов модели;\n",
    "    3) Анализ ошибок модели –> генерация идей;\n",
    "    4) Добавить регуляризацию;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-drink",
   "metadata": {},
   "source": [
    "<h3>Задание на семинаре: реализуем логистическую регрессию</h3>\n",
    "\n",
    "<p>Мы получаем оптимальные веса алгоритма градиентным спуском:</p>\n",
    "\n",
    "<p style=\"text-align:center\"><br />\n",
    "<br />\n",
    "<span class=\"math-tex\">\\(\\begin{bmatrix} w_{1}^{t+1}\\\\  ...\\\\ w_{m}^{t+1}\\\\  \\end{bmatrix} = \\begin{bmatrix} w_{1}^{t}\\\\  ...\\\\ w_{m}^{t}\\\\  \\end{bmatrix} - \\alpha \\cdot  \\begin{bmatrix} \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})x_{1}^{(i)}\\\\  ...\\\\ \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})x_{m}^{(i)}\\\\  \\end{bmatrix}\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(b^{t+1} = b^{t} - \\alpha \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, max_iter=1e4, lr=0.001, tol=0.001, print_every=100):\n",
    "        \n",
    "        '''\n",
    "        max_iter – максимальное количеств\n",
    "        '''\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        '''\n",
    "        Обучение модели.\n",
    "        \n",
    "        X_train – матрица объектов для обучения\n",
    "        y_train – ответы на объектах для обучения\n",
    "        \n",
    "        X_val – матрица объектов для валидации\n",
    "        y_val – ответы на объектах для валидации\n",
    "        '''\n",
    "        \n",
    "        self.check_binary_clf_X_y(X_train, y_train)\n",
    "        self.check_binary_clf_X_y(X_val, y_val)\n",
    "                \n",
    "        n, m = X_train.shape\n",
    "        \n",
    "        self.weights = \n",
    "        self.bias = \n",
    "        \n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "        \n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "            \n",
    "            dJdw, dJdb = self.grads(X_train, y_train)\n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "                \n",
    "            self.weights = \n",
    "            self.bias = \n",
    "            \n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):  \n",
    "        \n",
    "        '''\n",
    "        Метод возвращает предсказанную метку класса на объектах X\n",
    "        '''\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        '''\n",
    "        Метод возвращает вероятность класса 1 на объектах X\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def grads(self, x, y):\n",
    "        \n",
    "        '''\n",
    "        Рассчёт градиентов\n",
    "        '''\n",
    "        y_hat = \n",
    "        \n",
    "        dJdw = \n",
    "        dJdb = \n",
    "        \n",
    "        self.check_grads(dJdw, dJdb)\n",
    "        \n",
    "        return dJdw, dJdb\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        '''\n",
    "        Сигмоида от x\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "        \n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "        \n",
    "        train_acc = accuracy_score(train_preds, y_train)\n",
    "        val_acc = accuracy_score(val_preds, y_val)\n",
    "        \n",
    "        print(f'{n_iter} completed. accuracy_score on train: {train_acc}, val: {val_acc}, grad_norm: {gradient_norm}')\n",
    "        \n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "        \n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным'\n",
    "                             f' числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "            \n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_binary_clf_X_y(X, y):\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "            \n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "            \n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "            \n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "\n",
    "                    \n",
    "        if sorted(np.unique([1, 0, 0])) != [0, 1]:\n",
    "            raise ValueError(f'Ответы на объектах должны быть только 0 или 1, а у нас np.unique(y) = {np.unique(y)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-cable",
   "metadata": {},
   "source": [
    "<h2>Домашнее задание</h2>\n",
    "\n",
    "<p>Воспользуемся реализованной моделью логистической регрессии, чтобы решить задачу определения пола пользователя Авито.</p>\n",
    "\n",
    "<p><a href=\"https://stepik.org/media/attachments/lesson/527992/binary_clf_data.csv\" rel=\"noopener noreferrer nofollow\">Данные</a> даны в сыром виде &ndash; айтемы и их категории, которые выкладывали покупатели на Авито. Целевая переменная: <em>gender.</em></p>\n",
    "\n",
    "<p>Вам необходимо разбить данные на train, val. Перед загрузкой файла с ответом убедитесь, что точность (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\" rel=\"noopener noreferrer nofollow\">accuracy</a>)&nbsp;на валидации не менее 0.7.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><strong>План действий</strong></p>\n",
    "\n",
    "<p>Сначала нужно преобразовать категории с помощью one-hot encoding. Далее необходимо агрегировать категории, в которых пользователи выкладывали объявления, чтобы получить вектор признаков для каждого объекта. В результате у каждого пользователя будет вектор признаков, содержащий количество айтемов, выложенных в каждой из возможных категорий.</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Убедитесь, что для каждого пользователя в выборке есть только один объект, каждый признак означает количество айтемов, выложенное этим пользователем в категории;</li>\n",
    "\t<li>Убедитесь, что после one-hot энкодинга каждая категория соответствует признаку,&nbsp;<strong>одинаковому в train, val и test.</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>Попробуйте варианты отбора признаков. Для борьбы с переобучением на редких категориях используйте регуляризацию. В качестве&nbsp;ответа загрузите файл с предсказанием пола для пользователей:</p>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<table align=\"center\" border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px\">\n",
    "\t<thead>\n",
    "\t\t<tr>\n",
    "\t\t\t<th style=\"text-align:center\">user_id</th>\n",
    "\t\t\t<th style=\"text-align:center\">gender</th>\n",
    "\t\t</tr>\n",
    "\t</thead>\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"text-align:center\">15424171</td>\n",
    "\t\t\t<td style=\"text-align:center\">male</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"text-align:center\">15454025</td>\n",
    "\t\t\t<td style=\"text-align:center\">female</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<p>Такой файл можно сформировать с помощью&nbsp;<code>test_predictions.to_csv(&#39;test_predictions.csv&#39;, index=False)</code>.</p>\n",
    "\n",
    "<p>После того, как получилось обучить модель, ответьте на вопрос: какие из категорий вносят наибольший вклад в вероятность класса &quot;мужчина&quot; и класса &quot;женщина&quot;?</p>\n",
    "\n",
    "<p>Например, если вы закодировали &quot;мужчина&quot; как 1, большие положительные веса при признаках будут означать большой вклад в вероятность класса 1, большие по модулю отрицательные веса будут вносить наибольший вклад в вероятность класса 0. Согласуется ли полученный результат с вашим жизненным опытом?</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
