{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virgin-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "def get_mape(y_predict, y_true):\n",
    "    return (abs(y_predict - y_true) / y_true).mean()\n",
    "\n",
    "def process_rooms_number(x):\n",
    "        \n",
    "    if pd.isna(x):\n",
    "        return 1\n",
    "    \n",
    "    if isinstance(x, int):\n",
    "        return x\n",
    "    \n",
    "    if x.isdigit():\n",
    "        return int(x)\n",
    "    \n",
    "    if x == 'Студия':\n",
    "        return 1\n",
    "    \n",
    "    if x == 'Своб. планировка':\n",
    "        return 1\n",
    "    \n",
    "    if x == '> 9':\n",
    "        return 10\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-bahamas",
   "metadata": {},
   "source": [
    "<h3>Реализуем линейную регрессию</h3>\n",
    "\n",
    "<p>Чаще всего алгоритмы машинного обучения реализуются в виде классов с обязательными методами <code>.fit()</code>, <code>.predict()</code>. </p>\n",
    "\n",
    "<p><code>.fit()</code> – обучить алгоритм на обучающей выборке;</p>\n",
    "\n",
    "<p><code>.predict()</code> – сделать предсказание на тестовых данных.</p>\n",
    "\n",
    "<p> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pediatric-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, max_iter=1e4, lr=0.001, tol=0.001, print_every=100, batch_size=None, l2_coef = 0):\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        self.l2_coef = l2_coef\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        self.check_regression_X_y(X_train, y_train)\n",
    "        self.check_regression_X_y(X_val, y_val)\n",
    "        \n",
    "        n, m = X_train.shape\n",
    "        \n",
    "        self.weights = np.zeros((m, 1))\n",
    "        self.bias = 0\n",
    "        \n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "        \n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "            \n",
    "            if self.batch_size:\n",
    "                random_ids = np.random.randint(0, X_train.shape[0], size=self.batch_size)\n",
    "                dJdw, dJdb = self.grads(X_train[random_ids], y_train[random_ids])\n",
    "            else:\n",
    "                dJdw, dJdb = self.grads(X_train, y_train)\n",
    "                \n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "                \n",
    "            self.weights = self.weights - self.lr * dJdw\n",
    "            self.bias = self.bias - self.lr * dJdb\n",
    "            \n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.weights) + self.bias\n",
    "    \n",
    "    def grads(self, X, y):\n",
    "        \n",
    "        y_hat = self.predict(X)\n",
    "        \n",
    "        dJdw = ((y_hat - y) * X).mean(axis=0, keepdims=True).T + (self.l2_coef * self.weights)\n",
    "        dJdb = (y_hat - y).mean()\n",
    "        \n",
    "        self.check_grads(dJdw, dJdb)\n",
    "        \n",
    "        return dJdw, dJdb\n",
    "    \n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "        \n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "        \n",
    "        MAPE_train = get_mape(train_preds, y_train)\n",
    "        MAPE_val = get_mape(val_preds, y_val)\n",
    "        \n",
    "        print(f'{n_iter} completed. MAPE on train: {MAPE_train}, val: {MAPE_val},  grad norm: {gradient_norm}')\n",
    "        \n",
    "        \n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "        \n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным '\n",
    "                             f'числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "            \n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "            \n",
    "        \n",
    "    @staticmethod\n",
    "    def check_regression_X_y(X, y):\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "            \n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "            \n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "            \n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "                    \n",
    "        if np.any([(not isinstance(value, numbers.Real)) for value in y.flatten()]):\n",
    "            raise ValueError(f'Ответы на объектах должны быть действительными числами!')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-photographer",
   "metadata": {},
   "source": [
    "<h3>Тестируем модель на простой задаче</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "painted-cycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 completed. MAPE on train: 0.5088891642967012, val: 0.5088891642967012,  grad norm: 0.0013875823192608524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.33234396],\n",
       "       [2.44345507],\n",
       "       [2.55456618],\n",
       "       [2.66622005]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 1],\n",
    "])\n",
    "y = np.array([[1], [2], [3], [4]])\n",
    "model = LinearRegression(lr=0.1)\n",
    "model.fit(X, y, X, y)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-longitude",
   "metadata": {},
   "source": [
    "<h3>Решаем задачу предсказания цены</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fleet-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('real_estate_novosibirsk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-chorus",
   "metadata": {},
   "source": [
    "<p>Чистим данные:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "korean-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['item_id'], keep='last')\n",
    "data = data.dropna(subset=['area'])\n",
    "data['rooms_number'] = data['rooms_number'].apply(process_rooms_number).copy()\n",
    "data = data[(data.price > 970000) & (data.price < 12700000)]\n",
    "data = data[(data.floor < 59)]\n",
    "\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "disturbed-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, train_price, val_price = train_test_split(data.drop('price', axis=1), data['price'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "brutal-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_price_estimator.csv')\n",
    "test, test_price = test_data.drop('price', axis=1), test_data['price']\n",
    "\n",
    "y_train = train_price.values.reshape(-1, 1)\n",
    "y_val = val_price.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-singer",
   "metadata": {},
   "source": [
    "### Делаем бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "entitled-copper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37614684131639187"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mape(y_predict=np.median(y_train), y_true=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-blade",
   "metadata": {},
   "source": [
    "### Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-square",
   "metadata": {},
   "source": [
    "1) Начинаем с простого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "every-irish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.24041646500108102, val: 0.23306769336189537,  grad norm: 30726.511087846946\n",
      "20000 completed. MAPE on train: 0.24589712566681887, val: 0.23837089080363735,  grad norm: 10236.612882422081\n",
      "30000 completed. MAPE on train: 0.2479166434933886, val: 0.2403367969259019,  grad norm: 3410.3528059199984\n",
      "40000 completed. MAPE on train: 0.24861017270627137, val: 0.24101314283237188,  grad norm: 1136.167440777104\n",
      "50000 completed. MAPE on train: 0.24884343579771137, val: 0.24124089689468017,  grad norm: 378.51698253641536\n",
      "60000 completed. MAPE on train: 0.24892167152761666, val: 0.2413174375000516,  grad norm: 126.10386543934003\n",
      "70000 completed. MAPE on train: 0.24894775093354468, val: 0.2413429790738306,  grad norm: 42.01181350459267\n",
      "80000 completed. MAPE on train: 0.24895643984622523, val: 0.24135148831207218,  grad norm: 13.996339190929458\n",
      "90000 completed. MAPE on train: 0.24895933457889513, val: 0.24135432318576006,  grad norm: 4.662914890135419\n",
      "100000 completed. MAPE on train: 0.2489602989662171, val: 0.24135526763091467,  grad norm: 1.553461585614544\n",
      "110000 completed. MAPE on train: 0.2489606202542298, val: 0.24135558227514514,  grad norm: 0.5175395549071522\n",
      "120000 completed. MAPE on train: 0.24896072729212299, val: 0.2413556870996459,  grad norm: 0.17241957781524894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x7fb23a857cd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[['area']].values\n",
    "X_val = val[['area']].values\n",
    "\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=140000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-easter",
   "metadata": {},
   "source": [
    "<p>Для того, чтобы начать ориентироваться в метрике решения задачи, очень важно построить одну или несколько простых моделей. Часто есть соблазн добавить все признаки сразу и обучить модель — мы так поступать не будем. Наоборот, мы будем постепенно добавлять признаки и следить за тем, что модель решает задачу лучше и лучше. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-motorcycle",
   "metadata": {},
   "source": [
    "2) Увеличиваем количество признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hawaiian-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.23871962878302797, val: 0.23047817188452926,  grad norm: 5971.194596934688\n",
      "20000 completed. MAPE on train: 0.2379776705986216, val: 0.22979156736052941,  grad norm: 2981.2001659882826\n",
      "30000 completed. MAPE on train: 0.2376233210814564, val: 0.22946355254736478,  grad norm: 1488.4047547623757\n",
      "40000 completed. MAPE on train: 0.23745039389094072, val: 0.22930322373574852,  grad norm: 743.106329884653\n",
      "50000 completed. MAPE on train: 0.23736518223078368, val: 0.22922384544850766,  grad norm: 371.0059483133193\n",
      "60000 completed. MAPE on train: 0.23732283386509392, val: 0.22918441660625552,  grad norm: 185.22976880746816\n",
      "70000 completed. MAPE on train: 0.23730173143630276, val: 0.2291648372041522,  grad norm: 92.47848291499318\n",
      "80000 completed. MAPE on train: 0.23729120934724846, val: 0.2291550820732042,  grad norm: 46.17114115787269\n",
      "90000 completed. MAPE on train: 0.23728595715888604, val: 0.2291502163088233,  grad norm: 23.05157057755291\n",
      "100000 completed. MAPE on train: 0.23728333493236792, val: 0.2291477903757101,  grad norm: 11.508810325455089\n",
      "110000 completed. MAPE on train: 0.23728202575009202, val: 0.2291465791955882,  grad norm: 5.745930181189332\n",
      "120000 completed. MAPE on train: 0.23728137212302403, val: 0.22914597449742918,  grad norm: 2.8687338407128777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x7fb2a4268d00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[['area', 'floors_in_house', 'floor']].values\n",
    "X_val = val[['area', 'floors_in_house', 'floor']].values\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-telling",
   "metadata": {},
   "source": [
    "Делаем новые признаки\n",
    "##### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "developmental-shoot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature\n",
       "0       a\n",
       "1       b\n",
       "2       a\n",
       "3       c"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_example = pd.DataFrame({'feature': ['a', 'b', 'a', 'c']})\n",
    "ohe_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "remarkable-bedroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit_transform(ohe_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "moved-confusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.22941138841977596, val: 0.2214656951419709,  grad norm: 3647.0265280886033\n",
      "20000 completed. MAPE on train: 0.22898330262542557, val: 0.22107901423381854,  grad norm: 1877.7821362414481\n",
      "30000 completed. MAPE on train: 0.22876834702795182, val: 0.22088535115025887,  grad norm: 966.8330488208313\n",
      "40000 completed. MAPE on train: 0.22865911290323174, val: 0.22078753820223476,  grad norm: 497.8033001009539\n",
      "50000 completed. MAPE on train: 0.22860336310282905, val: 0.22073743719250502,  grad norm: 256.3091175811085\n",
      "60000 completed. MAPE on train: 0.22857470881141922, val: 0.22071173106457354,  grad norm: 131.96851797041745\n",
      "70000 completed. MAPE on train: 0.22855995928779066, val: 0.22069849753009907,  grad norm: 67.94799147105498\n",
      "80000 completed. MAPE on train: 0.22855237397369385, val: 0.22069169034386688,  grad norm: 34.98508292709264\n",
      "90000 completed. MAPE on train: 0.22854846956406355, val: 0.22068818826240125,  grad norm: 18.0131303501314\n",
      "100000 completed. MAPE on train: 0.22854645926042222, val: 0.22068638510961003,  grad norm: 9.274606142478552\n",
      "110000 completed. MAPE on train: 0.2285454241946597, val: 0.22068545670174153,  grad norm: 4.775312087783089\n",
      "120000 completed. MAPE on train: 0.2285448912596788, val: 0.22068497868281015,  grad norm: 2.4587141691624534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x7fb2a4271400>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_house_type_transformer = OneHotEncoder(sparse=False)\n",
    "train_ohe_house_type = ohe_house_type_transformer.fit_transform(train[['type_of_house']])\n",
    "val_ohe_house_type = ohe_house_type_transformer.transform(val[['type_of_house']])\n",
    "\n",
    "ohe_district_transformer = OneHotEncoder(sparse=False)\n",
    "train_ohe_district = ohe_district_transformer.fit_transform(train[['district']])\n",
    "val_ohe_district = ohe_district_transformer.transform(val[['district']])\n",
    "\n",
    "X_train_extended = np.hstack([X_train, train_ohe_house_type, train_ohe_district])\n",
    "X_val_extended = np.hstack([X_val, val_ohe_house_type, val_ohe_district])\n",
    "\n",
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1)\n",
    "model.fit(X_train_extended, y_train, X_val_extended, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "turned-regulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 completed. MAPE on train: 0.23254081234291066, val: 0.22442068758615033,  grad norm: 658037.874978649\n",
      "20000 completed. MAPE on train: 0.26376928837410457, val: 0.25473641506809247,  grad norm: 22336440.81460733\n",
      "30000 completed. MAPE on train: 0.22182840171636697, val: 0.2143910447481423,  grad norm: 1127192.0637011616\n",
      "40000 completed. MAPE on train: 0.26831470816747927, val: 0.26663597976173176,  grad norm: 48856537.591485366\n",
      "50000 completed. MAPE on train: 0.48198800924905066, val: 0.47081908071673495,  grad norm: 74294586.61583692\n",
      "60000 completed. MAPE on train: 0.21644183141255355, val: 0.2094568795631596,  grad norm: 8696303.950223094\n",
      "70000 completed. MAPE on train: 0.23870088069593806, val: 0.2304146701114391,  grad norm: 7402759.066630338\n",
      "80000 completed. MAPE on train: 0.25759225058820023, val: 0.248726239616521,  grad norm: 14170360.493276702\n",
      "90000 completed. MAPE on train: 0.22381859340688098, val: 0.21626022445365173,  grad norm: 2991314.949142468\n",
      "100000 completed. MAPE on train: 0.23244777874196135, val: 0.22908979249224148,  grad norm: 47026222.26721351\n",
      "110000 completed. MAPE on train: 0.21173171254298204, val: 0.20553482779410776,  grad norm: 14706405.505795682\n",
      "120000 completed. MAPE on train: 0.2878822702951543, val: 0.27845649142865503,  grad norm: 21924613.79763579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegression at 0x7fb23a75cca0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(lr=6e-4, max_iter=120000, print_every=10000, tol=0.1, batch_size=8196)\n",
    "model.fit(X_train_extended, y_train, X_val_extended, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-grammar",
   "metadata": {},
   "source": [
    "### Задание на семинаре: попробовать улучшить метрику MAPE до 15.8% (топ-1 без ML с первой недели).\n",
    "\n",
    "Варианты путей для улучшения:\n",
    "\n",
    "    1) Делать новые признаки из существующих;\n",
    "    2) Препроцессинг данных, целевой переменной - постпроцессинг ответов модели;\n",
    "    3) Анализ ошибок модели –> генерация идей;\n",
    "    4) Добавить регуляризацию;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-drink",
   "metadata": {},
   "source": [
    "<h3>Задание на семинаре: реализуем логистическую регрессию</h3>\n",
    "\n",
    "<p>Мы получаем оптимальные веса алгоритма градиентным спуском:</p>\n",
    "\n",
    "<p style=\"text-align:center\"><br />\n",
    "<br />\n",
    "<span class=\"math-tex\">\\(\\begin{bmatrix} w_{1}^{t+1}\\\\  ...\\\\ w_{m}^{t+1}\\\\  \\end{bmatrix} = \\begin{bmatrix} w_{1}^{t}\\\\  ...\\\\ w_{m}^{t}\\\\  \\end{bmatrix} - \\alpha \\cdot  \\begin{bmatrix} \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})x_{1}^{(i)}\\\\  ...\\\\ \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})x_{m}^{(i)}\\\\  \\end{bmatrix}\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\"><span class=\"math-tex\">\\(b^{t+1} = b^{t} - \\alpha \\sum_{i=1}^{n} (\\frac{1}{1+exp(w^{T}x^{(i)})} - y^{(i)})\\)</span></p>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, max_iter=1e4, lr=0.001, tol=0.001, print_every=100):\n",
    "        \n",
    "        '''\n",
    "        max_iter – максимальное количеств\n",
    "        '''\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.tol = tol\n",
    "        self.print_every = print_every\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        '''\n",
    "        Обучение модели.\n",
    "        \n",
    "        X_train – матрица объектов для обучения\n",
    "        y_train – ответы на объектах для обучения\n",
    "        \n",
    "        X_val – матрица объектов для валидации\n",
    "        y_val – ответы на объектах для валидации\n",
    "        '''\n",
    "        \n",
    "        self.check_binary_clf_X_y(X_train, y_train)\n",
    "        self.check_binary_clf_X_y(X_val, y_val)\n",
    "                \n",
    "        n, m = X_train.shape\n",
    "        \n",
    "        self.weights = \n",
    "        self.bias = \n",
    "        \n",
    "        n_iter = 0\n",
    "        gradient_norm = np.inf\n",
    "        \n",
    "        while n_iter < self.max_iter and gradient_norm > self.tol:\n",
    "            \n",
    "            dJdw, dJdb = self.grads(X_train, y_train)\n",
    "            gradient_norm = np.linalg.norm(np.hstack([dJdw.flatten(), [dJdb]]))\n",
    "                \n",
    "            self.weights = \n",
    "            self.bias = \n",
    "            \n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % self.print_every == 0:\n",
    "                self.print_metrics(X_train, y_train, X_val, y_val, n_iter, gradient_norm)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):  \n",
    "        \n",
    "        '''\n",
    "        Метод возвращает предсказанную метку класса на объектах X\n",
    "        '''\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        '''\n",
    "        Метод возвращает вероятность класса 1 на объектах X\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def grads(self, x, y):\n",
    "        \n",
    "        '''\n",
    "        Рассчёт градиентов\n",
    "        '''\n",
    "        y_hat = \n",
    "        \n",
    "        dJdw = \n",
    "        dJdb = \n",
    "        \n",
    "        self.check_grads(dJdw, dJdb)\n",
    "        \n",
    "        return dJdw, dJdb\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        '''\n",
    "        Сигмоида от x\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def print_metrics(self, X_train, y_train, X_val, y_val, n_iter, gradient_norm):\n",
    "        \n",
    "        train_preds = self.predict(X_train)\n",
    "        val_preds = self.predict(X_val)\n",
    "        \n",
    "        train_acc = accuracy_score(train_preds, y_train)\n",
    "        val_acc = accuracy_score(val_preds, y_val)\n",
    "        \n",
    "        print(f'{n_iter} completed. accuracy_score on train: {train_acc}, val: {val_acc}, grad_norm: {gradient_norm}')\n",
    "        \n",
    "    def check_grads(self, dJdw, dJdb):\n",
    "        \n",
    "        if not isinstance(dJdb, numbers.Real):\n",
    "            raise ValueError(f'Производная по параметру b должна быть действительным'\n",
    "                             f' числом, как и сам параметр b, а у нас {dJdb} типа {type(dJdb)}')\n",
    "            \n",
    "        if dJdw.shape != self.weights.shape:\n",
    "            raise ValueError(f'Размерность градиента по параметрам w должна совпадать с самим вектором w, '\n",
    "                             f'а у нас dJdw.shape = {dJdw.shape} не совпадает с weight.shape = {self.weights.shape}')\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_binary_clf_X_y(X, y):\n",
    "        \n",
    "        if X.shape[0] == 0:\n",
    "            raise ValueError(f'X и y не должны быть пустыми, а у нас X.shape = {X.shape} и y.shape = {y.shape}')\n",
    "            \n",
    "        if np.isnan(X).any():\n",
    "            raise ValueError(f'X не должен содержать \"not a number\" (np.nan)')\n",
    "            \n",
    "        if np.isnan(y).any():\n",
    "            raise ValueError(f'y не должен содержать \"not a number\" (np.nan)')\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'Длина X и y должна быть одинаковой, а у нас X.shape = {X.shape}, y.shape = {y.shape}')\n",
    "            \n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(f'y - вектор ответов должен быть размерности (m, 1), а у нас y.shape = {y.shape}')\n",
    "\n",
    "                    \n",
    "        if sorted(np.unique([1, 0, 0])) != [0, 1]:\n",
    "            raise ValueError(f'Ответы на объектах должны быть только 0 или 1, а у нас np.unique(y) = {np.unique(y)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-cable",
   "metadata": {},
   "source": [
    "<h2>Домашнее задание</h2>\n",
    "\n",
    "<p>Воспользуемся реализованной моделью логистической регрессии, чтобы решить задачу определения пола пользователя Авито.</p>\n",
    "\n",
    "<p><a href=\"https://stepik.org/media/attachments/lesson/527992/binary_clf_data.csv\" rel=\"noopener noreferrer nofollow\">Данные</a> даны в сыром виде &ndash; айтемы и их категории, которые выкладывали покупатели на Авито. Целевая переменная: <em>gender.</em></p>\n",
    "\n",
    "<p>Вам необходимо разбить данные на train, val. Перед загрузкой файла с ответом убедитесь, что точность (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\" rel=\"noopener noreferrer nofollow\">accuracy</a>)&nbsp;на валидации не менее 0.7.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><strong>План действий</strong></p>\n",
    "\n",
    "<p>Сначала нужно преобразовать категории с помощью one-hot encoding. Далее необходимо агрегировать категории, в которых пользователи выкладывали объявления, чтобы получить вектор признаков для каждого объекта. В результате у каждого пользователя будет вектор признаков, содержащий количество айтемов, выложенных в каждой из возможных категорий.</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Убедитесь, что для каждого пользователя в выборке есть только один объект, каждый признак означает количество айтемов, выложенное этим пользователем в категории;</li>\n",
    "\t<li>Убедитесь, что после one-hot энкодинга каждая категория соответствует признаку,&nbsp;<strong>одинаковому в train, val и test.</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>Попробуйте варианты отбора признаков. Для борьбы с переобучением на редких категориях используйте регуляризацию. В качестве&nbsp;ответа загрузите файл с предсказанием пола для пользователей:</p>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<table align=\"center\" border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px\">\n",
    "\t<thead>\n",
    "\t\t<tr>\n",
    "\t\t\t<th style=\"text-align:center\">user_id</th>\n",
    "\t\t\t<th style=\"text-align:center\">gender</th>\n",
    "\t\t</tr>\n",
    "\t</thead>\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"text-align:center\">15424171</td>\n",
    "\t\t\t<td style=\"text-align:center\">male</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"text-align:center\">15454025</td>\n",
    "\t\t\t<td style=\"text-align:center\">female</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "\n",
    "<p style=\"text-align:center\">&nbsp;</p>\n",
    "\n",
    "<p>Такой файл можно сформировать с помощью&nbsp;<code>test_predictions.to_csv(&#39;test_predictions.csv&#39;, index=False)</code>.</p>\n",
    "\n",
    "<p>После того, как получилось обучить модель, ответьте на вопрос: какие из категорий вносят наибольший вклад в вероятность класса &quot;мужчина&quot; и класса &quot;женщина&quot;?</p>\n",
    "\n",
    "<p>Например, если вы закодировали &quot;мужчина&quot; как 1, большие положительные веса при признаках будут означать большой вклад в вероятность класса 1, большие по модулю отрицательные веса будут вносить наибольший вклад в вероятность класса 0. Согласуется ли полученный результат с вашим жизненным опытом?</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
