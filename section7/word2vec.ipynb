{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd0ea33-971d-4345-bd67-abf87fd63ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe5dd90-46a8-4abf-8569-39ceb00eb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('suggest_train.csv')\n",
    "data = data.drop(columns=['item_id']).drop_duplicates()\n",
    "# train_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d219060a-1f04-4e7b-9cb4-85e7ac163b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b261395b-16f4-4643-aacf-9b1d13bc4cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('suggest_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa475158-9cce-4ce1-82ab-3e5b3565bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_titles = train_data.title\n",
    "val_titles = val_data.title\n",
    "\n",
    "y_train = train_data.category_id\n",
    "y_val = val_data.category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9621d812-447e-42fe-8720-1a3d3a3f4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models.callbacks import CallbackAny2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ae5dd1-4ee0-4314-b732-9c6c5fc1a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss - self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss\n",
    "        \n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f'Epoch {self.epoch}')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee09504-71a1-4cd4-9c86-664e104b929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_PATTERN = '(?u)\\\\b\\\\w\\\\w+\\\\b'  # паттерн для токенизации возьмем из векторайзеров sklearn\n",
    "reg_exp = re.compile(pattern=WORD_PATTERN)  # скомпилируем регулярное выражение\n",
    "sentences = [reg_exp.findall(s.lower()) for s in train_data.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc60c54-aec0-444c-b5c7-9219262803ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['свадебные', 'бокалы'],\n",
       " ['слон', 'качалка'],\n",
       " ['ножки', 'для', 'ванной'],\n",
       " ['20', '01', 'на', '12', 'дней', 'вьетнам', 'galaxy', 'hotel'],\n",
       " ['продам', 'шкатулку']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff7537a-ca5f-4684-8c97-8ec4f69021c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f68334-0986-4c8e-a4a7-39a12af577fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model_1 = FastText(window=3)\n",
    "w2v_model_2 = Word2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d4cb6e7-6a26-47c3-b97a-579889050db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model_1.build_vocab(sentences)\n",
    "# w2v_model_1.train(\n",
    "#     corpus_iterable=sentences,\n",
    "#     total_examples=w2v_model_1.corpus_count,\n",
    "#     epochs=30,\n",
    "#     compute_loss=True,\n",
    "#     callbacks=[LossLogger()]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38e5cc60-8dc0-45ce-9d5e-7aafb1f4c4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 44834.48046875\n",
      "Loss after epoch 1: 45136.95703125\n",
      "Loss after epoch 2: 43011.890625\n",
      "Loss after epoch 3: 37886.03125\n",
      "Loss after epoch 4: 34526.390625\n",
      "Loss after epoch 5: 32910.09375\n",
      "Loss after epoch 6: 31464.71875\n",
      "Loss after epoch 7: 30423.625\n",
      "Loss after epoch 8: 29196.5\n",
      "Loss after epoch 9: 28086.28125\n",
      "Loss after epoch 10: 27185.75\n",
      "Loss after epoch 11: 26178.53125\n",
      "Loss after epoch 12: 25263.09375\n",
      "Loss after epoch 13: 24696.09375\n",
      "Loss after epoch 14: 23829.875\n",
      "Loss after epoch 15: 23210.3125\n",
      "Loss after epoch 16: 22411.0\n",
      "Loss after epoch 17: 21815.4375\n",
      "Loss after epoch 18: 21089.6875\n",
      "Loss after epoch 19: 20655.0\n",
      "Loss after epoch 20: 20255.5\n",
      "Loss after epoch 21: 19832.25\n",
      "Loss after epoch 22: 19399.8125\n",
      "Loss after epoch 23: 19027.3125\n",
      "Loss after epoch 24: 18850.25\n",
      "Loss after epoch 25: 18451.0625\n",
      "Loss after epoch 26: 18048.1875\n",
      "Loss after epoch 27: 17857.6875\n",
      "Loss after epoch 28: 17599.9375\n",
      "Loss after epoch 29: 17257.0625\n",
      "Loss after epoch 30: 17009.9375\n",
      "Loss after epoch 31: 17006.6875\n",
      "Loss after epoch 32: 16926.5625\n",
      "Loss after epoch 33: 16587.5625\n",
      "Loss after epoch 34: 16424.6875\n",
      "Loss after epoch 35: 16185.0\n",
      "Loss after epoch 36: 16153.5625\n",
      "Loss after epoch 37: 15980.75\n",
      "Loss after epoch 38: 15986.9375\n",
      "Loss after epoch 39: 15913.0625\n",
      "Loss after epoch 40: 15744.8125\n",
      "Loss after epoch 41: 15667.9375\n",
      "Loss after epoch 42: 12267.3125\n",
      "Loss after epoch 43: 15691.5625\n",
      "Loss after epoch 44: 15444.875\n",
      "Loss after epoch 45: 15510.1875\n",
      "Loss after epoch 46: 15473.75\n",
      "Loss after epoch 47: 15759.875\n",
      "Loss after epoch 48: 15647.875\n",
      "Loss after epoch 49: 15761.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1474494, 2789000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_to_vec\n",
    "w2v_model_2.build_vocab(sentences)\n",
    "w2v_model_2.train(\n",
    "    corpus_iterable=sentences,\n",
    "    total_examples=w2v_model_2.corpus_count,\n",
    "    epochs=50,\n",
    "    compute_loss=True,\n",
    "    callbacks=[LossLogger()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "445b20cd-ebf8-45a4-ba4f-f9d2bff99c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iphone6', 0.8824732899665833),\n",
       " ('iphone', 0.876761257648468),\n",
       " ('5c', 0.8694149255752563),\n",
       " ('4s', 0.8631072044372559),\n",
       " ('чехлы', 0.8402438163757324),\n",
       " ('другие', 0.8169571757316589),\n",
       " ('5s', 0.8095609545707703),\n",
       " ('силиконовый', 0.8049678206443787),\n",
       " ('чёрный', 0.8037092089653015),\n",
       " ('пленка', 0.7992513179779053)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_2.wv.similar_by_word('айфон')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5005005-5921-45c4-a735-fb1267e0db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd320604-c101-4ba1-afae-27e35e9240af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe \n",
    "ohe_title_encoder = CountVectorizer()\n",
    "ohe_title_encoder.fit(train_data.title)\n",
    "ohe_title_encoded_train = ohe_title_encoder.transform(train_data.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88fdccb7-9020-4ca6-9df9-3603927402ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "tfidf = TfidfTransformer(smooth_idf=False)\n",
    "tfidf.fit(ohe_title_encoded_train)\n",
    "tfidf_title_encoded_train = tfidf.transform(ohe_title_encoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ac865e3-6b58-4733-997e-ab941040c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "788f38ab-9abc-4335-abd6-46c30b8b3fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecTransformer:\n",
    "    \n",
    "    def __init__(self, w2v_model,CountVectorizer,tfidf, word_pattern):\n",
    "        \n",
    "        self.w2v_model = w2v_model\n",
    "        \n",
    "        self.tfidf = tfidf\n",
    "        self.CountVectorizer = CountVectorizer\n",
    "        \n",
    "        self.feature_names = CountVectorizer.get_feature_names_out()\n",
    "        \n",
    "        self.word_pattern = word_pattern\n",
    "        \n",
    "        self.re = re.compile(pattern=self.word_pattern)\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X_countvec_transformed = self.CountVectorizer.transform(X)\n",
    "        tfidf_matrix = self.tfidf.transform(X_countvec_transformed)\n",
    "        \n",
    "        X_transformed = np.zeros(\n",
    "            (\n",
    "                len(X), \n",
    "                self.w2v_model.wv.vector_size * 3\n",
    "            )\n",
    "        )\n",
    "        for i, title in enumerate(X):\n",
    "            \n",
    "            title_sum_vector_1 = np.zeros((self.w2v_model.wv.vector_size,))\n",
    "            title_max_vector_1 = np.zeros((self.w2v_model.wv.vector_size,))\n",
    "            title_avg_vector_1 = np.zeros((self.w2v_model.wv.vector_size,))\n",
    "            \n",
    "            tokens = self.re.findall(title.lower())\n",
    "            \n",
    "            n = 0\n",
    "            for token in tokens:\n",
    "                # if token in self.w2v_model.wv.key_to_index:\n",
    "                    # get embeding from w2v\n",
    "                embeding_1 = self.w2v_model.wv.get_vector(token)\n",
    "\n",
    "                # get weight from tfidf\n",
    "                if token in self.feature_names:\n",
    "                    ind = np.where(self.feature_names == token)[0][0]\n",
    "                    weight = tfidf_matrix[i, ind]\n",
    "                else:\n",
    "                    weight = 1\n",
    "\n",
    "                title_sum_vector_1 += weight * embeding_1\n",
    "                title_max_vector_1 = np.max(np.c_[title_max_vector_1, embeding_1], axis=1)\n",
    "                title_avg_vector_1 += embeding_1\n",
    "                    \n",
    "                n += 1\n",
    "                    \n",
    "                    \n",
    "            if n!=0:\n",
    "                title_avg_vector_1 = title_avg_vector_1 / n\n",
    "                    \n",
    "                            \n",
    "            X_transformed[i] = np.hstack(\n",
    "                (title_sum_vector_1, \n",
    "                title_max_vector_1, \n",
    "                title_avg_vector_1)\n",
    "            )\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0163c6b3-55f8-420f-8c60-80e2df2d4cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1872"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model_2.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e643ea1-51b6-41d7-a7c2-67f1a09f83a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a1e7a8d-5365-4a8b-89c7-def670e5ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_top3(y_pred: np.array, y_true: np.array):\n",
    "    return np.mean((y_true.reshape(-1, 1) == y_pred).any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0c635b5-391e-43ae-a642-dbe8af650d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_transformer = Word2VecTransformer(\n",
    "    w2v_model=w2v_model_2, \n",
    "    CountVectorizer = ohe_title_encoder, \n",
    "    tfidf=tfidf,\n",
    "    word_pattern=WORD_PATTERN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df81bcbe-2309-4171-adc1-4db7bc196690",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'слон' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_w2v \u001b[38;5;241m=\u001b[39m \u001b[43mw2v_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_titles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m val_w2v \u001b[38;5;241m=\u001b[39m w2v_transformer\u001b[38;5;241m.\u001b[39mtransform(val_titles\u001b[38;5;241m.\u001b[39mvalues)\n",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36mWord2VecTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# if token in self.w2v_model.wv.key_to_index:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;66;03m# get embeding from w2v\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     embeding_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw2v_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# get weight from tfidf\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:447\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:421\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'слон' not present\""
     ]
    }
   ],
   "source": [
    "train_w2v = w2v_transformer.transform(train_titles.values)\n",
    "val_w2v = w2v_transformer.transform(val_titles.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "3ced538e-7f6b-4e8a-bb2c-1ea497bd0df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.38800251, -0.04533114, -0.01970021, ..., -0.1230011 ,\n",
       "         0.02525388, -0.16313565],\n",
       "       [-0.44136335,  0.03456653,  0.22971979, ..., -0.00945737,\n",
       "        -0.05280595,  0.04317823],\n",
       "       [-0.76579437,  0.02022166,  0.05134596, ...,  0.00675785,\n",
       "        -0.11255291, -0.13456968],\n",
       "       ...,\n",
       "       [-0.55980463,  0.01737561,  0.06687669, ..., -0.0305613 ,\n",
       "         0.11434018, -0.05742053],\n",
       "       [-0.33899556, -0.09315239, -0.09609361, ..., -0.24829175,\n",
       "         0.07249144, -0.32100859],\n",
       "       [-0.58394822, -0.07218426,  0.21554952, ..., -0.09008254,\n",
       "         0.08304159, -0.06869227]])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "3c26ae97-7e2e-4d3d-9f03-1cba17ecf7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "b3abfd16-23e5-4808-9643-9ad11a01f9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_on_w2v = LGBMClassifier()\n",
    "# LogisticRegression(solver='liblinear')\n",
    "model_on_w2v.fit(train_w2v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "65eaa96a-cc45-49bf-a332-15568d571a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_hat = model_on_w2v.predict_proba(val_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "b8568d1e-741b-47f3-a09a-3a95df02c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_top3 = np.argsort(-y_val_hat, axis=1)[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "c69e69cb-82b8-4d25-8691-dd43c4fbd0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6922017084596308"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_top3(y_val_top3, y_val.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aac1d7a-932b-4332-b897-e6d8faf5ba0e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "914f4b9e-2be4-468e-923d-269631677ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_w2v = w2v_transformer.transform(test_data.title.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "33a53d03-4e09-44de-9e90-b48af98478aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_hat = model_on_w2v.predict_proba(test_w2v)\n",
    "y_val_top3 = np.argsort(-y_val_hat, axis=1)[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "0767a11a-7797-47d7-a1bd-1f03c1ea9377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  2, 26],\n",
       "       [30, 31, 15],\n",
       "       [21, 19, 37],\n",
       "       ...,\n",
       "       [34, 43, 32],\n",
       "       [26, 17, 44],\n",
       "       [52, 15, 53]])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "8f3cb56a-9df4-4a37-9dd3-b7b498f05c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_val_top3).to_csv('solution.csv', header=['top1', 'top2', 'top3'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637bcf8-2073-4a37-83e4-b8e24c5a5023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
